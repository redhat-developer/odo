= Test Guide
:toc: macro
:toc-title:
:toclevels: 1

toc::[]

== Setting up test environment

Requires *Go 1.13* and *Ginkgo latest version*

Testing happens with the above version. Developers are advised to stick to this version if they can but it is not compulsory for Go version.

Run `make goget-tools` target to set up the test integration test environment. Unit test does not require any precondition, run `make test` to validate unit tests.   

== Tests

We use unit, integration and e2e (End to end) tests.

=== Unit tests

Unit tests for `odo` functions are written using package
https://godoc.org/k8s.io/client-go/kubernetes/fake[fake]. This allows us to create a fake client, and then mock the API calls defined under link:https://github.com/openshift/client-go[OpenShift client-go] and link:https://godoc.org/k8s.io/client-go[k8s client-go].

The tests are written in golang using the https://golang.org/pkg/testing/[pkg/testing] package.

==== Writing unit tests using the fake Kubernetes client

. Identify the APIs used by the function to be tested.
. Initialize the fake client along with the relevant client sets.
The following example explains the initialization of fake clients and the creation of fake objects.
+
The function `GetImageStreams` in https://github.com/openshift/odo/blob/main/pkg/occlient/occlient.go[`pkg/occlient.go`] fetches imagestream objects through the API:
+
[source,go]
----
func (c *Client) GetImageStreams(namespace string) ([]imagev1.ImageStream, error) {
        imageStreamList, err := c.imageClient.ImageStreams(namespace).List(metav1.ListOptions{})
        if err != nil {
                return nil, errors.Wrap(err, "unable to list imagestreams")
        }
        return imageStreamList.Items, nil
}
----

 .. For writing the tests, start by initializing the fake client using the function `FakeNew()` which initializes the image clientset harnessed by `GetImageStreams` function:
+
[source,go]
----
client, fkclientset := FakeNew()
----
.. In the `GetImageStreams` functions, the list of imagestreams is fetched through the API. While using fake client, this list can be emulated using a https://github.com/kubernetes/client-go/blob/master/testing/fake.go[`PrependReactor`] interface:
+
[source,go]
----
 fkclientset.ImageClientset.PrependReactor("list", "imagestreams", func(action ktesting.Action) (bool, runtime.Object, error) {
         return true, fakeImageStreams(tt.args.name, tt.args.namespace), nil
     })
----
+
The `PrependReactor` expects `resource` and `verb` to be passed in as arguments. Get this information by looking at the link:https://github.com/openshift/client-go/blob/master/image/clientset/versioned/typed/image/v1/fake/fake_imagestream.go[`List` function for fake imagestream]:
+
[source,go]
----
func (c *FakeImageStreams) List(opts v1.ListOptions) (result *image_v1.ImageStreamList, err error) {
        obj, err := c.Fake.Invokes(testing.NewListAction(imagestreamsResource, imagestreamsKind, c.ns, opts), &image_v1.ImageStreamList{})
    ...
}
 func NewListAction(resource schema.GroupVersionResource, kind schema.GroupVersionKind, namespace string, opts interface{}) ListActionImpl {
        action := ListActionImpl{}
        action.Verb = "list"
        action.Resource = resource
        action.Kind = kind
        action.Namespace = namespace
        labelSelector, fieldSelector, _ := ExtractFromListOptions(opts)
        action.ListRestrictions = ListRestrictions{labelSelector, fieldSelector}
         return action
}
----
+
The `List` function internally calls `NewListAction` defined in link:https://github.com/kubernetes/client-go/blob/master/testing/actions.go[`k8s.io/client-go/testing/actions.go`].
From these functions, we see that the `resource` and `verb` to be passed into the `PrependReactor` interface are `imagestreams` and `list` respectively.
+
You can see the entire test function `TestGetImageStream` in link:https://github.com/openshift/odo/blob/main/pkg/occlient/occlient_test.go[`pkg/occlient/occlient_test.go`].
+
NOTE: You can use environment variable `CUSTOM_HOMEDIR` to specify a custom home directory. It can be used in environments where a user and home directory are not resolvable.

. In the case where functions fetch or create new objects through the APIs, add a https://godoc.org/k8s.io/client-go/testing#Fake.AddReactor[reactor] interface returning fake objects.
. Verify the objects returned.

NOTE: Refer https://github.com/golang/go/wiki/LearnTesting for Go best practices on unit testing.

=== Integration and e2e tests

*Prerequisites for OpenShift cluster:*

* A `minishift` or OpenShift 3.11 environment with Service Catalog enabled:
+
----
$ MINISHIFT_ENABLE_EXPERIMENTAL=y minishift start --extra-clusterup-flags "--enable=*,service-catalog,automation-service-broker,template-service-broker"
----
OR
* A `crc` environment for 4.* local cluster:
+
Follow link:https://github.com/code-ready/crc#documentation[`crc`] installation guide.
+
OR
* A 4.* cluster hosted remotely

*Prerequisites for Kubernetes cluster:*

* A `kubernetes` environment set up with single node cluster:
+
For a single node `kubernetes` cluster install link:https://kubernetes.io/docs/tasks/tools/install-minikube/[`Minikube`]

NOTE: Make sure that `odo` and `oc` binaries are in `$PATH`. Use the cloned odo directory to launch tests on 3.11 and 4.* clusters. To communicate with `Kubernetes` cluster use `kubectl`. Run `make configure-supported-311-is` to get odo supported images on a 3.11 cluster spun up by `Minishift` or `oc cluster up` locally. Similarly a 4.* cluster needs to be configured before launching the tests against it. The files `kubeadmin-password` and `kubeconfig` which contain cluster login details should be present in the `auth` directory and it should reside in the same directory as `Makefile`. If it is not present in the auth directory, please create it. Then run `make configure-installer-tests-cluster` to configure the 4.* cluster. 

*Integration tests:*

Integration tests utilize link:https://github.com/onsi/ginkgo[`Ginkgo`] and its preferred matcher library link:https://github.com/onsi/gomega[`Gomega`] which define sets of test cases (spec). As per ginkgo test file comprises specs and these test file are controlled by test suite. 

Test and test suite files are located in `tests/integration` directory and can be called using `make test-integration`. 

To run ONE individual test, you can either:

* Supply the name via command-line: `ginkgo -focus="When executing catalog list without component directory" tests/integration/`
* Modify the `It` statement to `Fit` and run `ginkgo tests/integration/`

Integration tests validate and focus on specific fields of odo functionality or individual commands. For example, `cmd_app_test.go` or `generic_test.go`.

If you are running `operatorhub` tests then you need to install certain operators on the cluster -

- Etcd Cluster-wide operator
- Service Binding operator
- Postgres operator

Etcd and Service Binding operator can be installed by running link:https://github.com/openshift/odo/blob/main/scripts/configure-cluster/common/setup-operators.sh[setup-operator.sh]. To install Postgres operator you can run the following commands

----
  oc new-project odo-operator-test
  # Let developer user have access to the project
  oc adm policy add-role-to-user edit developer

  oc create -f - <<EOF
  apiVersion: operators.coreos.com/v1
  kind: OperatorGroup
  metadata:
    generateName: odo-operator-test-
    namespace: odo-operator-test
  spec:
    targetNamespaces:
    - odo-operator-test
EOF

  oc create -f - <<EOF
  apiVersion: operators.coreos.com/v1alpha1
  kind: Subscription
  metadata:
    name: postgresql-operator-dev4devs-com
    namespace: odo-operator-test
  spec:
    channel: alpha
    name: postgresql-operator-dev4devs-com
    source: community-operators
    sourceNamespace: openshift-marketplace
    installPlanApproval: "Automatic"
EOF

----

Note - the `odo-operator-test` is the namespace where postgres operatorhub tests execute by default. You can configure that by setting `REDHAT_POSTGRES_OPERATOR_PROJECT` env variable.

*E2e tests:*

E2e (End to end) uses the same library as integration test. E2e tests and test suite files are located in `tests/e2escenarios` directory and can be called using `.PHONY` within `makefile`. Basically end to end (e2e) test contains user specific scenario that is combination of some features/commands in a single test file.

*How to write:*

Refer to the odo clean test link:https://github.com/openshift/odo/blob/main/tests/template/template_cleantest_test.go[`template`].

*Test guidelines:*

Please follow certain protocol before contributing to odo tests. This helps in how to contribute in link:https://github.com/openshift/odo/tree/main/tests[`odo tests`]. For better understanding of writing test please refer Ginkgo link:https://onsi.github.io/ginkgo/#getting-ginkgo[documentation] and Ginkgo's preferred matcher library Gomega link:http://onsi.github.io/gomega/[documentation].

* Before writing tests (Integration/e2e) scenario make sure that the test scenario (Integration or e2e) is identified properly.
+

----
For example:
In storage feature test, storage command will be tested properly includes positive, negative and corner cases whereas in e2e scenario only one or two storage command will be tested in e2e scenario like `create component -> link -> add storage -> certain operation -> delete storage -> unlink -> delete component`.
----
+

* Create a new test file for a new feature and make sure that the feature file name should add proper sense. If the feature test file is already present then update the same test file with new scenario.
+

----
For example:
For storage feature, a new storage test file is created. If new functionality is added to the storage feature then same file will be updated with new scenario. Naming of the test file should follow a common format like `cmd_<feature name>_test`. So the storage feature test file name will be `cmd_storage_test.go`. Same naming convention can be used for e2e test like `e2e_<release name>_test` or `e2e_<full scenario name>_test`.
----
+

* Test description should make sense of what it implements in the specs. Use proper test description in `Describe` block
+

----
For example:
For storage feature, the appropriate test description would be `odo storage command tests`.

var _ = Describe("odo storage command tests", func() {
    [...]
})
----
+

* For a better understanding of what a spec does, use proper description in `Context` and `it` block
+

----
For example:
Context("when running help for storage command", func() {
	It("should display the help", func() {
		[...]
	})
})
----
+

* Don't create a new test spec for the steps which can be run with the existing specs.
+ 

* Spec level conditions, pre and post requirements should be run in ginkgo built-in tear down steps `JustBeforeEach` and `JustAfterEach`
+

* Due to parallel test run support make sure that the spec should run in isolation, otherwise the test result will lead to race condition. To achieve this ginkgo provides some in build functions `BeforeEach`, `AfterEach` etc.
+

----
For example:
var _ = Describe("odo generic", func() {
    var project string
	var context string
	var oc helper.OcRunner
    BeforeEach(func() {
	    oc = helper.NewOcRunner("oc")
	    SetDefaultEventuallyTimeout(10 * time.Minute)
	    context = helper.CreateNewContext()
    })
    AfterEach(func() {
	    os.RemoveAll(context)
    })
    Context("deploying a component with a specific image name", func() {
        JustBeforeEach(func() {
            os.Setenv("GLOBALODOCONFIG", filepath.Join(context, "config.yaml"))
            project = helper.CreateRandProject()
        })

        JustAfterEach(func() {
            helper.DeleteProject(project)
            os.Unsetenv("GLOBALODOCONFIG")
        })
        It("should deploy the component", func() {
            helper.CopyExample(filepath.Join("source", "nodejs"), context)
            helper.Cmd("odo", "create", "nodejs:latest", "testversioncmp", "--project", project, "--context", context).ShouldPass()
            helper.Cmd("odo", "push", "--context", context).ShouldPass()
            helper.Cmd("odo", "delete", "-f", "--context", context).ShouldPass()
        })
    })
})
----
+

* Don’t create new test file for issues(bug) and try to add some scenario for each bug fix if applicable
+

* Don’t use unnecessary text validation in `Expect` of certain command output. Only validation of key text specific to that scenario would be enough.
+

----
For example:
While running multiple push on same component without changing any source file.

helper.Cmd("odo", "push", "--show-log", "--context", context+"/nodejs-ex")
output := helper.Cmd("odo", "push", "--show-log", "--context", context+"/nodejs-ex").ShouldPass().Out()
Expect(output).To(ContainSubstring("No file changes detected, skipping build"))
----
+

* If oc, odo or generic library you are looking for is not present in helper package then create a new library function as per the scenario requirement. Avoid unnecessary function implementation within test files. Check to see if there is a helper function already implemented.
+

* If you are looking for delay with a specific feature test, don't use hard time.Sleep() function. Yes, you can use but as a polling interval of maximum duration. Check the link:https://github.com/openshift/odo/tree/main/tests/helper[`helper package`] for more such reference.
+

----
For example:
func RetryInterval(maxRetry, intervalSeconds int, program string, args ...string) string {
	for i := 0; i < maxRetry; i++ {
		session := CmdRunner(program, args...)
		session.Wait()
		if session.ExitCode() == 0 {
			time.Sleep(time.Duration(intervalSeconds) * time.Second)
		} else {
			Consistently(session).ShouldNot(gexec.Exit(0), runningCmd(session.Command))
			return string(session.Err.Contents())
		}
	}
	Fail(fmt.Sprintf("Failed after %d retries", maxRetry))
	return ""
}
----
or in Ginkgo there is an in-built link:http://onsi.github.io/ginkgo/#asynchronous-tests[`timeout feature`].
+

* The test spec should run in parallel (Default) or sequentially as per choice. Check test template for reference.
+

* Run tests on local env before pushing PRs

*Test variables:*

There are some test environment variable that helps to get more control over the test run and it's results

* TEST_EXEC_NODES: Env variable TEST_EXEC_NODES is used to pass spec execution type (parallel or sequential) for ginkgo tests. To run the specs sequentially use TEST_EXEC_NODES=1, otherwise by default the specs are run in parallel on 2 ginkgo test node. Any TEST_EXEC_NODES value greater than one runs the spec in parallel on the same number of ginkgo test nodes.

* SLOW_SPEC_THRESHOLD: Env variable SLOW_SPEC_THRESHOLD is used for ginkgo tests. After this time (in second), ginkgo marks test as slow. The default value is set to 120s.

* GINKGO_TEST_ARGS: Env variable GINKGO_TEST_ARGS is used to get control over enabling test flags against each test target run. For example, To enable verbosity export or set env GINKGO_TEST_ARGS like `GINKGO_TEST_ARGS=-v`.

* UNIT_TEST_ARGS: Env variable UNIT_TEST_ARGS is used to get control over enabling test flags along with go test. For example, To enable verbosity export or set env UNIT_TEST_ARGS like `UNIT_TEST_ARGS=-v`.

*Running integration tests on Openshift:*

For running tests on a 3.11 cluster, login to the cluster using the required credentials. For example `odo login -u <user_name> -p <password> <server_URL>`. In case of 4.* cluster, `make configure-installer-tests-cluster` performs the login operation required to run the test. By default, the tests are run against the `odo` binary placed in the $PATH which is created by the command `make`. Integration tests can be run in two ways, parallel and sequential. To control the parallel run, use the environment variable `TEST_EXEC_NODES`. For example, the component test can be run as following:

* To run the test in parallel, on a test cluster (By default the test will run in parallel on two ginkgo test node):

+
Run component command integration tests
+
----
$ make test-cmp-e2e
----
+

* To run the component command integration tests sequentially or on single ginkgo test node:
+
Run component command integration tests
+
----
$ TEST_EXEC_NODES=1 make test-cmd-cmp
----

NOTE: To see the number of available integration test file for validation, press `tab` just after writing `make test-cmd-`. However there is a test file `generic_test.go` which handles certain test specs easily and we can run it parallelly by calling `make test-generic`. By calling `make test-integration`, the whole suite will run all the specs in parallel on two ginkgo test node except `service` and `link` irrespective of service catalog status in the cluster. However `make test-integration-service-catalog` runs all specs of service and link tests in parallel on a cluster having service catalog enabled. `make test-odo-login-e2e` doesn't honour environment variable `TEST_EXEC_NODES`. So by default it runs login and logout command integration test suites on a single ginkgo test node sequentially to avoid race conditions during a parallel run.

*Running integration tests on Kubernetes:*

By default, the link:https://github.com/openshift/odo/tree/main/tests/integration/devfile[`integration tests`] for devfile feature, which is in experimental mode, run against `kubernetes` cluster. For more information on Experimental mode, please read link:https://github.com/openshift/odo/blob/main/docs/dev/experimental-mode.adoc:[`odo experimental mode`] document.

The tests are run against the `odo` binary placed in the PATH which is created by the command `make`. Integration tests can be run in two ways (parallel and sequential). To control the parallel run use environment variable `TEST_EXEC_NODES`. For example, the devfile tests can be run

* To run the tests on Kubernetes cluster:

+
Set the `KUBERNETES` environment variable
+
----
$ export KUBERNETES=true
----

+
Enable the experimental mode
+
----
$ export ODO_EXPERIMENTAL=true
----
+
OR
+
----
$ odo preference set Experimental true -f
----

* To run the test in parallel, on a test cluster (By default the test will run in parallel on two ginkgo test node):

+
Run catalog command integration tests
+
----
$ make test-cmd-devfile-catalog
----
+

* To run the catalog command integration tests sequentially or on single ginkgo test node:
+
Run catalog command integration tests
+
----
$ TEST_EXEC_NODES=1 make test-cmd-devfile-catalog
----

NOTE: To see the number of available integration test files for validation, press `tab` keb just after writing `make test-cmd-devfile-`. By calling `make test-integration-devfile`, the suite will run all test specs in parallel on two ginkgo test nodes.

*Running e2e tests:*

(E2e) End to end test run behaves in the similar way like integration test does. To see the number of available e2e test file for execution, press tab just after writing `make test-e2e-`. For e2e suite level execution of all e2e test spec use `make test-e2e-all`. For example

* To run the java e2e test in parallel, on a test cluster (By default the component test will run in parallel on two ginkgo test node):
----

